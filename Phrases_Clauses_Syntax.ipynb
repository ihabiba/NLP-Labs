{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+Zz5rywab6RA4oCpZRxo3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ihabiba/NLP-Labs/blob/main/Phrases_Clauses_Syntax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phrase Chunking with NLTK"
      ],
      "metadata": {
        "id": "PBWzI5KbrUkn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03VEh111lZ_K",
        "outputId": "09a46211-9fc6-42d6-bcd3-4eddac7e0345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.chunk import RegexpParser\n",
        "\n",
        "# Download required NLTK resources (run once – if they’re already downloaded, this will just skip)\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentences to test phrase chunking\n",
        "sentences = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"A beautiful butterfly landed on the colorful flower.\",\n",
        "    \"The experienced teacher explained the complex concept clearly.\"\n",
        "]\n",
        "\n",
        "# Define grammar for chunking\n",
        "# NP: Noun Phrase\n",
        "# PP: Prepositional Phrase\n",
        "# VP: Verb Phrase\n",
        "grammar = r\"\"\"\n",
        "    NP: {<DT|PP\\$>?<JJ>*<NN.*>+}\n",
        "    PP: {<IN><NP>}\n",
        "    VP: {<VB.*><NP|PP|CLAUSE>+}\n",
        "\"\"\"\n",
        "\n",
        "# Create a chunk parser based on the grammar above\n",
        "cp = RegexpParser(grammar)"
      ],
      "metadata": {
        "id": "BJ08ngwFsCup"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_phrase_chunking():\n",
        "    \"\"\"\n",
        "    Demonstrates basic noun phrase chunking using regular expressions.\n",
        "    \"\"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        print(\"\\nSentence:\", sentence)\n",
        "\n",
        "        # 1. Tokenize the sentence into words\n",
        "        tokens = word_tokenize(sentence)\n",
        "\n",
        "        # 2. Tag each token with its Part-of-Speech (POS) label\n",
        "        pos_tags = pos_tag(tokens)\n",
        "        print(\"POS Tags:\", pos_tags)\n",
        "\n",
        "        # 3. Parse the POS-tagged sentence into a chunk tree\n",
        "        tree = cp.parse(pos_tags)\n",
        "        print(\"Parse Tree:\")\n",
        "        print(tree)\n",
        "\n",
        "        # 4. Extract noun phrases (NP) from the tree\n",
        "        noun_phrases = []\n",
        "        for subtree in tree.subtrees():\n",
        "            if subtree.label() == 'NP':\n",
        "                np_text = ' '.join(word for word, tag in subtree.leaves())\n",
        "                noun_phrases.append(np_text)\n",
        "\n",
        "        print(\"Extracted Noun Phrases:\", noun_phrases)\n",
        "# Run demo\n",
        "demo_phrase_chunking()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiwoZ_e3sKla",
        "outputId": "bd5a5d54-9ecf-47f1-f52f-47736c448b76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: The quick brown fox jumps over the lazy dog.\n",
            "POS Tags: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n",
            "Parse Tree:\n",
            "(S\n",
            "  (NP The/DT quick/JJ brown/NN fox/NN)\n",
            "  (VP jumps/VBZ (PP over/IN (NP the/DT lazy/JJ dog/NN)))\n",
            "  ./.)\n",
            "Extracted Noun Phrases: ['The quick brown fox', 'the lazy dog']\n",
            "\n",
            "Sentence: A beautiful butterfly landed on the colorful flower.\n",
            "POS Tags: [('A', 'DT'), ('beautiful', 'JJ'), ('butterfly', 'NN'), ('landed', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('colorful', 'JJ'), ('flower', 'NN'), ('.', '.')]\n",
            "Parse Tree:\n",
            "(S\n",
            "  (NP A/DT beautiful/JJ butterfly/NN)\n",
            "  (VP landed/VBD (PP on/IN (NP the/DT colorful/JJ flower/NN)))\n",
            "  ./.)\n",
            "Extracted Noun Phrases: ['A beautiful butterfly', 'the colorful flower']\n",
            "\n",
            "Sentence: The experienced teacher explained the complex concept clearly.\n",
            "POS Tags: [('The', 'DT'), ('experienced', 'JJ'), ('teacher', 'NN'), ('explained', 'VBD'), ('the', 'DT'), ('complex', 'JJ'), ('concept', 'NN'), ('clearly', 'RB'), ('.', '.')]\n",
            "Parse Tree:\n",
            "(S\n",
            "  (NP The/DT experienced/JJ teacher/NN)\n",
            "  (VP explained/VBD (NP the/DT complex/JJ concept/NN))\n",
            "  clearly/RB\n",
            "  ./.)\n",
            "Extracted Noun Phrases: ['The experienced teacher', 'the complex concept']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **Justify why chunking is important in NLP pipeline**\n",
        "#### Chunking groups words into meaningful phrases (like NP and VP), which gives structure to the sentence. This helps downstream tasks by focusing on useful units instead of individual words.\n",
        "\n",
        "###  **Compare chunking and tokenization process**\n",
        "#### Tokenization splits text into words. Chunking groups those words (after POS tagging) into larger units like noun phrases. Tokenization = breaking; chunking = grouping.\n"
      ],
      "metadata": {
        "id": "TNwoWAzwvuJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Below is the modified version of the code that extracts and displays Noun Phrases (NP), Verb Phrases (VP), and Pronoun Phrases (PRONP)**"
      ],
      "metadata": {
        "id": "DWkfO1hRwYvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_phrase_chunking():\n",
        "    \"\"\"\n",
        "    Demonstrates chunking of Noun Phrases, Verb Phrases, and Pronoun Phrases.\n",
        "    \"\"\"\n",
        "    for sentence in sentences:\n",
        "        print(\"\\nSentence:\", sentence)\n",
        "\n",
        "        # Tokenize and POS tag\n",
        "        tokens = word_tokenize(sentence)\n",
        "        pos_tags = pos_tag(tokens)\n",
        "        print(\"POS Tags:\", pos_tags)\n",
        "\n",
        "        # Parse into a chunk tree\n",
        "        tree = cp.parse(pos_tags)\n",
        "        print(\"Parse Tree:\")\n",
        "        print(tree)\n",
        "\n",
        "        # Lists for each type of phrase\n",
        "        noun_phrases = []\n",
        "        verb_phrases = []\n",
        "        pronoun_phrases = []\n",
        "\n",
        "        # Extract phrases by label\n",
        "        for subtree in tree.subtrees():\n",
        "            label = subtree.label()\n",
        "            phrase_text = ' '.join(word for word, tag in subtree.leaves())\n",
        "\n",
        "            if label == 'NP':\n",
        "                noun_phrases.append(phrase_text)\n",
        "            elif label == 'VP':\n",
        "                verb_phrases.append(phrase_text)\n",
        "            elif label == 'PRONP':\n",
        "                pronoun_phrases.append(phrase_text)\n",
        "\n",
        "        print(\"Extracted Noun Phrases (NP):\", noun_phrases)\n",
        "        print(\"Extracted Verb Phrases (VP):\", verb_phrases)\n",
        "        print(\"Extracted Pronoun Phrases (PRONP):\", pronoun_phrases)\n",
        "\n",
        "# Run the demo\n",
        "demo_phrase_chunking()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiDZTSnpsYql",
        "outputId": "8a9c782b-4145-40a5-a8d5-d8e1ba4c840f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: The quick brown fox jumps over the lazy dog.\n",
            "POS Tags: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n",
            "Parse Tree:\n",
            "(S\n",
            "  (NP The/DT quick/JJ brown/NN fox/NN)\n",
            "  (VP jumps/VBZ (PP over/IN (NP the/DT lazy/JJ dog/NN)))\n",
            "  ./.)\n",
            "Extracted Noun Phrases (NP): ['The quick brown fox', 'the lazy dog']\n",
            "Extracted Verb Phrases (VP): ['jumps over the lazy dog']\n",
            "Extracted Pronoun Phrases (PRONP): []\n",
            "\n",
            "Sentence: A beautiful butterfly landed on the colorful flower.\n",
            "POS Tags: [('A', 'DT'), ('beautiful', 'JJ'), ('butterfly', 'NN'), ('landed', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('colorful', 'JJ'), ('flower', 'NN'), ('.', '.')]\n",
            "Parse Tree:\n",
            "(S\n",
            "  (NP A/DT beautiful/JJ butterfly/NN)\n",
            "  (VP landed/VBD (PP on/IN (NP the/DT colorful/JJ flower/NN)))\n",
            "  ./.)\n",
            "Extracted Noun Phrases (NP): ['A beautiful butterfly', 'the colorful flower']\n",
            "Extracted Verb Phrases (VP): ['landed on the colorful flower']\n",
            "Extracted Pronoun Phrases (PRONP): []\n",
            "\n",
            "Sentence: The experienced teacher explained the complex concept clearly.\n",
            "POS Tags: [('The', 'DT'), ('experienced', 'JJ'), ('teacher', 'NN'), ('explained', 'VBD'), ('the', 'DT'), ('complex', 'JJ'), ('concept', 'NN'), ('clearly', 'RB'), ('.', '.')]\n",
            "Parse Tree:\n",
            "(S\n",
            "  (NP The/DT experienced/JJ teacher/NN)\n",
            "  (VP explained/VBD (NP the/DT complex/JJ concept/NN))\n",
            "  clearly/RB\n",
            "  ./.)\n",
            "Extracted Noun Phrases (NP): ['The experienced teacher', 'the complex concept']\n",
            "Extracted Verb Phrases (VP): ['explained the complex concept']\n",
            "Extracted Pronoun Phrases (PRONP): []\n",
            "\n",
            "Sentence: He said that she will help us.\n",
            "POS Tags: [('He', 'PRP'), ('said', 'VBD'), ('that', 'IN'), ('she', 'PRP'), ('will', 'MD'), ('help', 'VB'), ('us', 'PRP'), ('.', '.')]\n",
            "Parse Tree:\n",
            "(S\n",
            "  (PRONP He/PRP)\n",
            "  (VP said/VBD)\n",
            "  that/IN\n",
            "  (PRONP she/PRP)\n",
            "  will/MD\n",
            "  (VP help/VB)\n",
            "  (PRONP us/PRP)\n",
            "  ./.)\n",
            "Extracted Noun Phrases (NP): []\n",
            "Extracted Verb Phrases (VP): ['said', 'help']\n",
            "Extracted Pronoun Phrases (PRONP): ['He', 'she', 'us']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependent and Independent Clauses with spaCy"
      ],
      "metadata": {
        "id": "QTeveo3-z9Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ],
      "metadata": {
        "id": "ccHhA5if0BXq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_clauses(text):\n",
        "    \"\"\"\n",
        "    Identify independent and dependent clauses in a sentence.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "\n",
        "    print(f\"\\nSentence: {text}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Identify the root verb (forms the main/independent clause)\n",
        "    root = [token for token in doc if token.dep_ == \"ROOT\"][0]\n",
        "\n",
        "    print(\"\\nINDEPENDENT CLAUSE:\")\n",
        "    print(\"  Main verb:\", root.text)\n",
        "\n",
        "    independent_words = [root.text]\n",
        "\n",
        "    # Get subject and object of the main clause\n",
        "    for child in root.children:\n",
        "        if child.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
        "            print(\"  Subject:\", child.text)\n",
        "            independent_words.insert(0, child.text)\n",
        "        elif child.dep_ in [\"dobj\", \"attr\"]:\n",
        "            print(\"  Object:\", child.text)\n",
        "            independent_words.append(child.text)\n",
        "\n",
        "    print(\"  Clause:\", \" \".join(independent_words))\n",
        "\n",
        "    # Dependent clauses\n",
        "    print(\"\\nDEPENDENT CLAUSES:\")\n",
        "    dependent_labels = {\n",
        "        'advcl': 'Adverbial Clause',\n",
        "        'ccomp': 'Complement Clause',\n",
        "        'xcomp': 'Complement Clause',\n",
        "        'relcl': 'Relative Clause',\n",
        "        'acl': 'Clausal Modifier'\n",
        "    }\n",
        "\n",
        "    found = False\n",
        "\n",
        "    for token in doc:\n",
        "        if token.dep_ in dependent_labels:\n",
        "            found = True\n",
        "            clause_words = [t.text for t in token.subtree]\n",
        "\n",
        "            marker = \"\"\n",
        "            for t in token.subtree:\n",
        "                if t.dep_ == \"mark\":\n",
        "                    marker = t.text\n",
        "\n",
        "            print(f\"\\n  Type: {dependent_labels[token.dep_]}\")\n",
        "            if marker:\n",
        "                print(\"  Marker:\", marker)\n",
        "            print(\"  Verb:\", token.text)\n",
        "            print(\"  Clause:\", \" \".join(clause_words))\n",
        "\n",
        "    if not found:\n",
        "        print(\"  None found (simple sentence)\")\n"
      ],
      "metadata": {
        "id": "KtjCob0k0E0J"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"The dog barks.\",\n",
        "    \"I stayed home because it was raining.\",\n",
        "    \"I believe that she is right.\",\n",
        "    \"The student who studied hard passed the exam.\",\n",
        "    \"She said that she would come when she finished her work.\",\n",
        "    \"Although it was difficult, we completed the project.\"\n",
        "]\n",
        "\n",
        "for s in sentences:\n",
        "    identify_clauses(s)\n",
        "    print(\"-\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1zBnajG0J4P",
        "outputId": "993b1386-35da-441a-8b98-21efd0e6ddf9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: The dog barks.\n",
            "============================================================\n",
            "\n",
            "INDEPENDENT CLAUSE:\n",
            "  Main verb: barks\n",
            "  Subject: dog\n",
            "  Clause: dog barks\n",
            "\n",
            "DEPENDENT CLAUSES:\n",
            "  None found (simple sentence)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sentence: I stayed home because it was raining.\n",
            "============================================================\n",
            "\n",
            "INDEPENDENT CLAUSE:\n",
            "  Main verb: stayed\n",
            "  Subject: I\n",
            "  Clause: I stayed\n",
            "\n",
            "DEPENDENT CLAUSES:\n",
            "\n",
            "  Type: Adverbial Clause\n",
            "  Marker: because\n",
            "  Verb: raining\n",
            "  Clause: because it was raining\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sentence: I believe that she is right.\n",
            "============================================================\n",
            "\n",
            "INDEPENDENT CLAUSE:\n",
            "  Main verb: believe\n",
            "  Subject: I\n",
            "  Clause: I believe\n",
            "\n",
            "DEPENDENT CLAUSES:\n",
            "\n",
            "  Type: Complement Clause\n",
            "  Marker: that\n",
            "  Verb: is\n",
            "  Clause: that she is right\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sentence: The student who studied hard passed the exam.\n",
            "============================================================\n",
            "\n",
            "INDEPENDENT CLAUSE:\n",
            "  Main verb: passed\n",
            "  Subject: student\n",
            "  Object: exam\n",
            "  Clause: student passed exam\n",
            "\n",
            "DEPENDENT CLAUSES:\n",
            "\n",
            "  Type: Relative Clause\n",
            "  Verb: studied\n",
            "  Clause: who studied\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sentence: She said that she would come when she finished her work.\n",
            "============================================================\n",
            "\n",
            "INDEPENDENT CLAUSE:\n",
            "  Main verb: said\n",
            "  Subject: She\n",
            "  Clause: She said\n",
            "\n",
            "DEPENDENT CLAUSES:\n",
            "\n",
            "  Type: Complement Clause\n",
            "  Marker: that\n",
            "  Verb: come\n",
            "  Clause: that she would come when she finished her work\n",
            "\n",
            "  Type: Adverbial Clause\n",
            "  Verb: finished\n",
            "  Clause: when she finished her work\n",
            "------------------------------------------------------------\n",
            "\n",
            "Sentence: Although it was difficult, we completed the project.\n",
            "============================================================\n",
            "\n",
            "INDEPENDENT CLAUSE:\n",
            "  Main verb: completed\n",
            "  Subject: we\n",
            "  Object: project\n",
            "  Clause: we completed project\n",
            "\n",
            "DEPENDENT CLAUSES:\n",
            "\n",
            "  Type: Adverbial Clause\n",
            "  Marker: Although\n",
            "  Verb: was\n",
            "  Clause: Although it was difficult\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Justify why breaking sentences into clauses is important in NLP pipeline**\n",
        "#### Breaking sentences into clauses helps the system understand the internal structure of complex sentences. Each clause carries a separate idea, so identifying them improves tasks like parsing, relation extraction, summarization, and meaning interpretation.\n",
        "\n",
        "### **What is the difference between a phrase and a clause?**\n",
        "#### A phrase has no subject–verb combination and cannot stand alone. A clause has a subject and a verb and can be independent or dependent.\n",
        "\n",
        "### **Identify the clauses that exists in the following sentence:**\n",
        "### “The man who lives next door said that he would help us if we needed anything.”\n",
        "#### Independent clause: **The man said**  \n",
        "#### Dependent clause (relative): **who lives next door**  \n",
        "#### Dependent clause (noun/complement): **that he would help us**  \n",
        "#### Dependent clause (conditional): **if we needed anything**\n"
      ],
      "metadata": {
        "id": "5W2BSePwyv3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarchical Syntax Tree with NLTK"
      ],
      "metadata": {
        "id": "uus3WKVMyK2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize, RegexpParser\n",
        "\n",
        "# Download NLTK resources (run once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuS1KBafwstT",
        "outputId": "e8cd9ab6-d3e5-46b1-9d16-3bddd4450ada"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text\n",
        "sample_text = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# Tokenize and POS tag\n",
        "tagged = pos_tag(word_tokenize(sample_text))\n",
        "\n",
        "# Define chunk patterns\n",
        "chunker = RegexpParser(\"\"\"\n",
        "    NP: {<DT>?<JJ>*<NN.*>+}   # Noun Phrases\n",
        "    P: {<IN>}                 # Prepositions\n",
        "    V: {<VB.*>}               # Verbs\n",
        "    PP: {<P><NP>}             # Prepositional Phrases\n",
        "    VP: {<V><NP|PP>*}         # Verb Phrases\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "A6jBhpCSyNTz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse and extract phrases\n",
        "output = chunker.parse(tagged)\n",
        "\n",
        "print(\"POS Tags:\")\n",
        "for word, tag in tagged:\n",
        "    print(f\"{word:10} -> {tag}\")\n",
        "\n",
        "print(\"\\nParsed Output:\")\n",
        "print(output)\n",
        "\n",
        "print(\"\\nTree Structure:\")\n",
        "output.pretty_print()\n",
        "\n",
        "print(\"\\nExtracted Phrases:\")\n",
        "for subtree in output.subtrees():\n",
        "    if subtree.label() != 'S':\n",
        "        phrase_text = ' '.join(word for word, tag in subtree.leaves())\n",
        "        print(f\"{subtree.label()}: {phrase_text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNzuBA6TyPlJ",
        "outputId": "0f8cccbe-ea5b-4802-ea13-ac1cc8aeef02"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags:\n",
            "The        -> DT\n",
            "quick      -> JJ\n",
            "brown      -> NN\n",
            "fox        -> NN\n",
            "jumps      -> VBZ\n",
            "over       -> IN\n",
            "the        -> DT\n",
            "lazy       -> JJ\n",
            "dog        -> NN\n",
            "\n",
            "Parsed Output:\n",
            "(S\n",
            "  (NP The/DT quick/JJ brown/NN fox/NN)\n",
            "  (VP (V jumps/VBZ) (PP (P over/IN) (NP the/DT lazy/JJ dog/NN))))\n",
            "\n",
            "Tree Structure:\n",
            "                                    S                                      \n",
            "           _________________________|_______________                        \n",
            "          |                                         VP                     \n",
            "          |                          _______________|_____                  \n",
            "          |                         |                     PP               \n",
            "          |                         |         ____________|_____            \n",
            "          NP                        V        P                  NP         \n",
            "   _______|________________         |        |       ___________|______     \n",
            "The/DT quick/JJ brown/NN fox/NN jumps/VBZ over/IN the/DT     lazy/JJ dog/NN\n",
            "\n",
            "\n",
            "Extracted Phrases:\n",
            "NP: The quick brown fox\n",
            "VP: jumps over the lazy dog\n",
            "V: jumps\n",
            "PP: over the lazy dog\n",
            "P: over\n",
            "NP: the lazy dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I196KV2lzqqe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_r8qOBJqyTQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Discuss the difference between a constituency and dependency trees.**\n",
        "#### A constituency tree shows how words group into hierarchical phrases (NP, VP, PP). A dependency tree shows how words depend on each other directly (head–dependent links). Constituency focuses on phrase structure; dependency focuses on grammatical relationships.\n",
        "\n",
        "### **What information can we derive from analysing a sentence using a hierarchical syntax tree?**\n",
        "#### It shows the sentence’s full structure: subjects, verbs, objects, modifiers, phrase boundaries, and how each part connects. This helps reveal roles, relationships, and the internal organization of the sentence.\n",
        "\n",
        "### **Explain how a hierarchical syntax tree supports NLP tasks like parsing or machine translation.**\n",
        "#### It provides a clear structural map of the sentence, letting NLP systems understand who does what to whom. This reduces ambiguity, improves alignment between languages, and helps parsers and MT models generate grammatically correct and semantically accurate output.\n"
      ],
      "metadata": {
        "id": "0bfBO8L8zipN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ASfBskiizh9N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}